{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%additional_python_modules duckdb==1.4.2",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nAdditional python modules to be included:\nduckdb==1.4.2\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 10\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 2\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 10 minutes.\nSetting Glue version to: 5.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 2\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 10\nSession ID: 38b98433-9c0d-4de9-9c66-cfeb613b7965\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\n--additional-python-modules duckdb==1.4.2\nWaiting for session 38b98433-9c0d-4de9-9c66-cfeb613b7965 to get into ready status...\nSession 38b98433-9c0d-4de9-9c66-cfeb613b7965 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import duckdb\nprint(\"Installed package\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Installed package\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import pandas as pd\nimport numpy as np",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def load_raw():\n    applications_train = pd.read_csv(\"s3://crisk-nico-prod/raw/applications/application_train.csv.gz\", compression='gzip')\n    applications_test = pd.read_csv(\"s3://crisk-nico-prod/raw/applications/application_test.csv.gz\", compression='gzip')\n    bureau = pd.read_csv(\"s3://crisk-nico-prod/raw/bureau/bureau_raw.csv.gz\", compression='gzip')\n    return applications_train, applications_test, bureau\n\ndef drop_redundancy(df, threshold = 0.9):\n\n    corr_matrix = df.select_dtypes(include=[np.number]).corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    df.drop(columns=to_drop, inplace=True)\n    print(f\"Dropped {len(to_drop)} correlated features\")\n\n# def days_to_years(df, cols):\n#     for col in cols:\n#         new_col = col.replace(\"DAYS\", \"YEARS\") \n#         df[new_col] = (df[col] / 365).abs()    \n#         df.drop(columns=[col], inplace=True)  \n#         print(f\"Dropped feature: {col}, New feature: {new_col}\")\n\n# def capping_children(df):\n#     df[\"CNT_CHILDREN_CAPPED\"] = df[\"CNT_CHILDREN\"].clip(upper=4)\n#     df.drop(columns=['CNT_CHILDREN'], inplace=True)\n\ndef drop_missing(df, threshold):\n    missing_ratio = df.isna().mean()\n    high_missing = missing_ratio[missing_ratio > threshold].index\n    df.drop(columns=high_missing, inplace=True)\n    print(f\"Dropped {len(high_missing)} features\")\n\ndef correlation_target(df, dtype):\n    nan_df = df[df.columns[df.isna().any()]]\n    nan_df_columns = (nan_df.select_dtypes(include=dtype).copy()).columns\n    for col in nan_df_columns:\n        print(df.groupby(df[col].isna())['TARGET'].mean())\n\ndef create_missing_flag(df, cols):\n    # Create missing flags for informative columns\n    for col in cols:\n        if col in df.columns:\n            df[f'{col}_IS_MISSING'] = df[col].isna().astype('Int8')\n\ndef fill_missing_numerical(df, cols, strategy):\n\n    if strategy == 'median': \n        # Median imputation\n\n        for col in cols:\n            df.fillna({col: df[col].median()}, inplace=True)\n\n    elif strategy == 'zero':\n        # 0-imputation for count-like features\n\n        for col in cols:\n            df.fillna({col: 0}, inplace=True)\n    else:\n        raise ValueError(\"Strategy must be 'median' or 'zero'\")\n        \n\ndef fill_missing_categorical(df, unknown_cols):\n\n    # Fill missing categories with 'unknown'\n    for col in unknown_cols:\n        if col in df.columns:\n            df[col] = df[col].fillna('Unknown')\n\ndef one_hot_encoding(df, cat_cols):\n    encoder = OneHotEncoder(drop='first', sparse_output = False, handle_unknown='ignore')\n    encoded_array = encoder.fit_transform(df[cat_cols])\n    \n    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n    encoded_df = pd.concat([df.drop(columns = cat_cols), encoded_df], axis=1)\n    assert len(encoded_df) == len(df), \"Row count changed during OHE!\"\n    \n    return encoded_df\n\ndef label_encoding(df, cats_col):\n    encoded_df = df.copy()\n    for col in cats_col:\n        encoder = LabelEncoder()\n        encoded_df[col] = encoder.fit_transform(df[col].astype(str))\n    return encoded_df",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "applications_train, applications_test, bureau = load_raw()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "drop_redundancy(applications_train)\ndrop_redundancy(applications_test)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "Dropped 35 correlated features\nDropped 35 correlated features\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# days_cols = [\"DAYS_BIRTH\", \"DAYS_EMPLOYED\"]\n\n# days_to_years(applications_train, days_cols)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "drop_missing(applications_train, threshold=0.4)\ndrop_missing(applications_test, threshold=0.4)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Dropped 18 features\nDropped 18 features\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "correlation_target(applications_train, 'number')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "AMT_ANNUITY\nFalse    0.080732\nTrue     0.000000\nName: TARGET, dtype: float64\nCNT_FAM_MEMBERS\nFalse    0.080729\nTrue     0.000000\nName: TARGET, dtype: float64\nEXT_SOURCE_2\nFalse    0.080733\nTrue     0.078788\nName: TARGET, dtype: float64\nEXT_SOURCE_3\nFalse    0.077665\nTrue     0.093119\nName: TARGET, dtype: float64\nOBS_30_CNT_SOCIAL_CIRCLE\nFalse    0.08088\nTrue     0.03526\nName: TARGET, dtype: float64\nDEF_30_CNT_SOCIAL_CIRCLE\nFalse    0.08088\nTrue     0.03526\nName: TARGET, dtype: float64\nDEF_60_CNT_SOCIAL_CIRCLE\nFalse    0.08088\nTrue     0.03526\nName: TARGET, dtype: float64\nDAYS_LAST_PHONE_CHANGE\nFalse    0.080729\nTrue     0.000000\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_HOUR\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_DAY\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_WEEK\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_MON\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_QRT\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\nAMT_REQ_CREDIT_BUREAU_YEAR\nFalse    0.077194\nTrue     0.103374\nName: TARGET, dtype: float64\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "flag_cols = [\n    'EXT_SOURCE_3', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n    'DEF_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n    'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n    'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'NAME_TYPE_SUITE', 'OCCUPATION_TYPE'\n]\ncreate_missing_flag(applications_train, cols = flag_cols)\ncreate_missing_flag(applications_test, cols = flag_cols)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "median_cols = [\n    'AMT_ANNUITY', 'CNT_FAM_MEMBERS', 'EXT_SOURCE_2',\n    'EXT_SOURCE_3', 'DAYS_LAST_PHONE_CHANGE'\n]\nfill_missing_numerical(applications_train, cols = median_cols, strategy='median')\nfill_missing_numerical(applications_test, cols = median_cols, strategy='median')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "zero_cols = [\n    'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n    'DEF_60_CNT_SOCIAL_CIRCLE',\n    'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n    'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n    'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR'\n]\nfill_missing_numerical(applications_train, cols = zero_cols, strategy='zero')\nfill_missing_numerical(applications_test, cols = zero_cols, strategy='zero')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "correlation_target(applications_train, 'object')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "NAME_TYPE_SUITE\nFalse    0.080841\nTrue     0.054180\nName: TARGET, dtype: float64\nOCCUPATION_TYPE\nFalse    0.087851\nTrue     0.065131\nName: TARGET, dtype: float64\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "unknown_cols = ['NAME_TYPE_SUITE', 'OCCUPATION_TYPE']\nfill_missing_categorical(applications_train,unknown_cols)\nfill_missing_categorical(applications_test,unknown_cols)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "drop_redundancy(bureau)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "Dropped 0 correlated features\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# days_cols = ['DAYS_CREDIT', 'DAYS_ENDDATE_FACT', 'DAYS_CREDIT_UPDATE']\n# days_to_years(bureau, days_cols)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "drop_missing(bureau, threshold = 0.4)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "Dropped 2 features\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "median_cols = [\n    'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT'\n]\nfill_missing_numerical(bureau, cols = median_cols, strategy='median')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "zero_cols = [\n    'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT'\n]\nfill_missing_numerical(bureau, cols = zero_cols, strategy='zero')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "con = duckdb.connect()\ncon.register('bureau', bureau)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "<_duckdb.DuckDBPyConnection object at 0x7fce0cb0b8f0>\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "bureau_agg = con.sql(\"WITH base AS( \" \\\n    # KEY/ID                        \n    \"SELECT SK_ID_CURR, \" \\\n    # CREDIT_ACTIVE: Count actives\n    \"SUM(CASE WHEN CREDIT_ACTIVE = 'Active' THEN 1 ELSE 0 END)   AS ACTIVE_COUNT, \" \\\n    \"SUM(CASE WHEN CREDIT_ACTIVE = 'Closed' THEN 1 ELSE 0 END)   AS CLOSED_COUNT, \" \\\n    \"SUM(CASE WHEN CREDIT_ACTIVE = 'Sold' THEN 1 ELSE 0 END)     AS SOLD_COUNT, \" \\\n    \"SUM(CASE WHEN CREDIT_ACTIVE = 'Bad debt' THEN 1 ELSE 0 END) AS BAD_DEBT_COUNT, \" \\\n    # CREDIT_CURRENCY: Count currency type (distinct)\n    \"COUNT(DISTINCT CREDIT_CURRENCY) AS CREDIT_CURRENCY_NUNIQUE,\" \\\n    # DAYS_CREDIT: Max, Min, Avg\n    \"MAX(DAYS_CREDIT) AS DAYS_CREDIT_MAX,\" \\\n    \"MIN(DAYS_CREDIT) AS DAYS_CREDIT_MIN,\" \\\n    \"AVG(DAYS_CREDIT) AS DAYS_CREDIT_AVG,\" \\\n    # SUM_CREDIT_DAY_OVERDUE: Sum\n    \"SUM(CREDIT_DAY_OVERDUE) AS CREDIT_DAY_OVERDUE_SUM,\" \\\n    # DAYS_CREDIT_ENDDATE max, min, avg\n    \"MAX(DAYS_CREDIT_ENDDATE) AS DAYS_CREDIT_ENDDATE_MAX,\" \\\n    \"MIN(DAYS_CREDIT_ENDDATE) AS DAYS_CREDIT_ENDDATE_MIN,\" \\\n    \"AVG(DAYS_CREDIT_ENDDATE) AS DAYS_CREDIT_ENDDATE_AVG,\" \\\n    # CNT_CREDIT_PROLONG sum, max\n    \"SUM(CNT_CREDIT_PROLONG) AS CNT_CREDIT_PROLONG_SUM,\" \\\n    \"MAX(CNT_CREDIT_PROLONG) AS CNT_CREDIT_PROLONG_MAX,\" \\\n    # AMT_CREDIT_SUM max, sum, avg\n    \"MAX(AMT_CREDIT_SUM) AS AMT_CREDIT_SUM_MAX,\" \\\n    \"SUM(AMT_CREDIT_SUM) AS AMT_CREDIT_SUM_SUM,\" \\\n    \"AVG(AMT_CREDIT_SUM) AS AMT_CREDIT_SUM_AVG,\" \\\n    # AMT_CREDIT_SUM_DEBT max, sum, avg\n    \"MAX(AMT_CREDIT_SUM_DEBT) AS AMT_CREDIT_SUM_DEBT_MAX,\" \\\n    \"SUM(AMT_CREDIT_SUM_DEBT) AS AMT_CREDIT_SUM_DEBT_SUM,\" \\\n    \"AVG(AMT_CREDIT_SUM_DEBT) AS AMT_CREDIT_SUM_DEBT_AVG,\" \\\n    # AMT_CREDIT_SUM_LIMIT max, sum, avg\n    \"MAX(AMT_CREDIT_SUM_LIMIT) AS AMT_CREDIT_SUM_LIMIT_MAX,\" \\\n    \"SUM(AMT_CREDIT_SUM_LIMIT) AS AMT_CREDIT_SUM_LIMIT_SUM,\" \\\n    \"AVG(AMT_CREDIT_SUM_LIMIT) AS AMT_CREDIT_SUM_LIMIT_AVG,\" \\\n    # AMT_CREDIT_SUM_OVERDUE max, sum, avg\n    \"MAX(AMT_CREDIT_SUM_OVERDUE) AS AMT_CREDIT_SUM_OVERDUE_MAX,\" \\\n    \"SUM(AMT_CREDIT_SUM_OVERDUE) AS AMT_CREDIT_SUM_OVERDUE_SUM,\" \\\n    \"AVG(AMT_CREDIT_SUM_OVERDUE) AS AMT_CREDIT_SUM_OVERDUE_AVG,\" \\\n    # CREDIT_TYPE count credit type (distinct)\n    \"COUNT(DISTINCT CREDIT_TYPE) AS CREDIT_TYPE_NUNIQUE,\" \\\n    # DAYS_CREDIT_UPDATE max, avg\n    \"MAX(DAYS_CREDIT_UPDATE) AS DAYS_CREDIT_UPDATE_MAX,\" \\\n    \"AVG(DAYS_CREDIT_UPDATE) AS DAYS_CREDIT_UPDATE_AVG,\" \\\n    # DAYS_ENDDATE_FACT mean\n    \"AVG(DAYS_ENDDATE_FACT) AS DAYS_ENDDATE_FACT_AVG,\" \\\n    # Portfolio size\n    \"COUNT(*) AS TOTAL_LOANS \" \\\n    \"FROM bureau GROUP BY SK_ID_CURR)\" \\\n\"SELECT * FROM base\").df()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "apps_train_merged_bureau_agg = applications_train.merge(bureau_agg, on='SK_ID_CURR', how='left').fillna(0)\napps_test_merged_bureau_agg = applications_test.merge(bureau_agg, on='SK_ID_CURR', how='left').fillna(0)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# apps_train_merged_bureau_agg[\"bucket_id\"] = apps_train_merged_bureau_agg[\"SK_ID_CURR\"] % 8\n\n# CURATED = \"s3://crisk-nico-prod/curated/apps_merged_bureau_agg\"\n\n# for bucket, df_part in apps_merged_bureau_agg.groupby(\"bucket_id\"):\n#     output_path = f\"{CURATED}/bucket_id={bucket}/data.parquet\"\n#     df_part.to_parquet(output_path, index=False)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\nCURATED = \"s3://crisk-nico-prod/curated/apps_merged_bureau_agg_1\"\n\napps_train_merged_bureau_agg[\"bucket_id\"] = apps_train_merged_bureau_agg[\"SK_ID_CURR\"] % 8\nspark_df = spark.createDataFrame(apps_train_merged_bureau_agg)\n\nspark_df.write.mode(\"overwrite\") \\\n    .partitionBy(\"bucket_id\") \\\n    .parquet(CURATED)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "CURATED = \"s3://crisk-nico-prod/curated/apps_merged_bureau_agg_test\"\n\napps_test_merged_bureau_agg[\"bucket_id\"] = apps_test_merged_bureau_agg[\"SK_ID_CURR\"] % 8\nspark_df = spark.createDataFrame(apps_test_merged_bureau_agg)\n\nspark_df.write.mode(\"overwrite\") \\\n    .partitionBy(\"bucket_id\") \\\n    .parquet(CURATED)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}